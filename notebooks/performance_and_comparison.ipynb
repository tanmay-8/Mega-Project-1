{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5e6d95",
   "metadata": {},
   "source": [
    "# Performance and accuracy\n",
    "\n",
    "Quick check of accuracy, latency, bytes, and CPU. Then we compare federated (with masking) to centralized and say if they’re effectively the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and global config\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import math\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths\n",
    "CENTRAL_METRICS = Path(\"outputs/metrics/centralized_metrics.csv\")\n",
    "FL_METRICS = Path(\"server/state/metrics_log.csv\")\n",
    "SERVER_PERF = Path(\"server/state/perf_log.csv\")\n",
    "CLIENT_PERF = Path(\"server/state/client_perf.csv\")\n",
    "ARTIFACTS_DIR = Path(\"outputs/plots\")\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc3a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics helpers\n",
    "\n",
    "def read_centralized(path: Path):\n",
    "    vals = {}\n",
    "    with path.open(\"r\", newline=\"\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            vals[row[\"metric\"]] = float(row[\"value\"])\n",
    "    return vals\n",
    "\n",
    "\n",
    "def read_fl_metrics(path: Path):\n",
    "    rounds, aucs, f1s = [], [], []\n",
    "    with path.open(\"r\", newline=\"\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            rounds.append(int(row[\"round\"]))\n",
    "            aucs.append(float(row[\"AUC\"]))\n",
    "            f1s.append(float(row[\"F1\"]))\n",
    "    return rounds, aucs, f1s\n",
    "\n",
    "\n",
    "def read_server_perf(path: Path):\n",
    "    rounds, duration, cpu, bytes_total = [], [], [], []\n",
    "    with path.open(\"r\", newline=\"\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            rounds.append(int(row[\"round\"]))\n",
    "            duration.append(float(row.get(\"duration_s\", 0)))\n",
    "            cpu.append(float(row.get(\"cpu_time_s\", 0)))\n",
    "            bytes_total.append(int(float(row.get(\"total_masked_bytes\", 0))))\n",
    "    return rounds, duration, cpu, bytes_total\n",
    "\n",
    "\n",
    "def read_client_perf(path: Path):\n",
    "    rows = []\n",
    "    with path.open(\"r\", newline=\"\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            rows.append({\n",
    "                \"client_id\": row[\"client_id\"],\n",
    "                \"round\": int(row[\"round\"]),\n",
    "                \"secagg\": int(row.get(\"secagg\", 0)),\n",
    "                \"local_train_time_s\": float(row.get(\"local_train_time_s\", 0)),\n",
    "                \"cpu_time_s\": float(row.get(\"cpu_time_s\", 0)),\n",
    "                \"upload_bytes\": int(float(row.get(\"upload_bytes\", 0))),\n",
    "            })\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "if not CENTRAL_METRICS.exists():\n",
    "    raise FileNotFoundError(f\"Missing centralized metrics: {CENTRAL_METRICS}\")\n",
    "if not FL_METRICS.exists():\n",
    "    raise FileNotFoundError(f\"Missing federated metrics log: {FL_METRICS}\")\n",
    "if not SERVER_PERF.exists():\n",
    "    raise FileNotFoundError(f\"Missing server perf log: {SERVER_PERF}\")\n",
    "if not CLIENT_PERF.exists():\n",
    "    raise FileNotFoundError(f\"Missing client perf log: {CLIENT_PERF}\")\n",
    "\n",
    "cen = read_centralized(CENTRAL_METRICS)\n",
    "fl_rounds, fl_aucs, fl_f1s = read_fl_metrics(FL_METRICS)\n",
    "sv_rounds, sv_dur, sv_cpu, sv_bytes = read_server_perf(SERVER_PERF)\n",
    "cl_rows = read_client_perf(CLIENT_PERF)\n",
    "\n",
    "cen_auc = cen.get(\"AUC\", 0.0)\n",
    "cen_f1 = cen.get(\"F1\", 0.0)\n",
    "fl_auc_last = fl_aucs[-1] if fl_aucs else 0.0\n",
    "fl_f1_last = fl_f1s[-1] if fl_f1s else 0.0\n",
    "print({\"centralized_auc\": cen_auc, \"federated_auc_last\": fl_auc_last, \"centralized_f1\": cen_f1, \"federated_f1_last\": fl_f1_last})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be984693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy curves and overlay centralized lines\n",
    "plt.figure(figsize=(8,5))\n",
    "if fl_rounds:\n",
    "    plt.plot(fl_rounds, fl_aucs, label='FL AUC')\n",
    "    plt.plot(fl_rounds, fl_f1s, label='FL F1')\n",
    "plt.axhline(cen_auc, color='C0', linestyle='--', alpha=0.6, label='Centralized AUC')\n",
    "plt.axhline(cen_f1, color='C1', linestyle='--', alpha=0.6, label='Centralized F1')\n",
    "plt.xlabel('Round')\n",
    "plt.ylabel('Metric')\n",
    "plt.title('Accuracy: Federated vs Centralized')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "acc_plot_path = ARTIFACTS_DIR / 'centralized_vs_fl_notebook.png'\n",
    "plt.tight_layout(); plt.savefig(acc_plot_path, dpi=150)\n",
    "print(f'Saved {acc_plot_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fdfdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latency per round and client upload bytes\n",
    "import statistics as stats\n",
    "\n",
    "# Latency line plot\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(sv_rounds, sv_dur, marker='o', label='Server latency (s)')\n",
    "plt.xlabel('Round'); plt.ylabel('Seconds'); plt.grid(True, alpha=0.3); plt.legend()\n",
    "lat_plot_path = ARTIFACTS_DIR / 'latency_per_round.png'\n",
    "plt.tight_layout(); plt.savefig(lat_plot_path, dpi=150)\n",
    "print(f'Saved {lat_plot_path}')\n",
    "\n",
    "# Bytes per client per round (boxplot)\n",
    "round_bytes = {}\n",
    "for row in cl_rows:\n",
    "    round_bytes.setdefault(row['round'], []).append(row['upload_bytes'])\n",
    "labels = sorted(round_bytes.keys())\n",
    "vals = [round_bytes[r] for r in labels]\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.boxplot(vals, labels=[str(x) for x in labels], showfliers=False)\n",
    "plt.xlabel('Round'); plt.ylabel('Upload bytes per client'); plt.title('Client communication per round'); plt.grid(True, alpha=0.3)\n",
    "bytes_plot_path = ARTIFACTS_DIR / 'bytes_per_client_per_round.png'\n",
    "plt.tight_layout(); plt.savefig(bytes_plot_path, dpi=150)\n",
    "print(f'Saved {bytes_plot_path}')\n",
    "\n",
    "# Summary stats\n",
    "avg_latency = stats.mean(sv_dur) if sv_dur else 0\n",
    "avg_server_cpu = stats.mean(sv_cpu) if sv_cpu else 0\n",
    "all_client_bytes = [b for arr in vals for b in arr]\n",
    "avg_bytes_per_client = stats.mean(all_client_bytes) if all_client_bytes else 0\n",
    "print({'avg_round_latency_s': round(avg_latency,4), 'avg_server_cpu_time_s': round(avg_server_cpu,4), 'avg_upload_bytes_per_client': int(avg_bytes_per_client)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy equivalence decision\n",
    "EPS = 0.01  # absolute tolerance\n",
    "auc_diff = abs(cen_auc - fl_auc_last)\n",
    "f1_diff = abs(cen_f1 - fl_f1_last)\n",
    "print({'auc_diff': auc_diff, 'f1_diff': f1_diff, 'epsilon': EPS})\n",
    "if auc_diff <= EPS and f1_diff <= EPS:\n",
    "    print(\"Conclusion: Federated (with Bonawitz) and centralized are equivalent within ±0.01 for AUC and F1.\")\n",
    "else:\n",
    "    print(\"Conclusion: Differences exceed the ±0.01 tolerance; consider more rounds or tuning.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
